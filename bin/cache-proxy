#!/usr/bin/env python3
import os
import socket
import logging

from hashlib import md5
from http.client import HTTPConnection, HTTPSConnection
from re import search

from nanoio import (
    run, recv, sendall, recv_until, wait_io, WAIT_WRITE, accept, spawn)


BUF_SIZE = 65536
CACHE_DIR = None


def parse_http_line(data):
    line, _, headers = data.partition(b'\r\n')
    return line.split(None, 2), headers


def get_header_value(data, name, default=None):
    m = search(rb'(?i)\r\n%s:\s*(.+)\s*\r\n' % name, data)
    if m:
        return m.group(1)
    return default


async def make_request(method, url):
    proto, _, host, qs = url.split(b'/', 3)
    cls = HTTPConnection if proto == b'http:' else HTTPSConnection
    h = cls(host.decode(), timeout=5)
    h.connect()
    h.sock.setblocking(False)
    await sendall(
        h.sock, b'%s /%s HTTP/1.1\r\nHost: %s\r\nConnection: close\r\n\r\n' % (
            method, qs, h.host.encode()))
    return h


def get_cache_path(url):
    proto, _, host, qs = url.split(b'/', 3)
    fname, _, _ = qs.partition(b'?')
    fname = fname.rstrip(b'/').split(b'/')[-1]
    return os.path.join(os.fsencode(CACHE_DIR), b'%s.%s.%s' % (host, fname, md5(url).hexdigest()[:10].encode()))


class ChunkedWriter:
    def __init__(self, fd):
        self.fd = fd
        self.next_count = 0
        self.prev = None
        self.end = False
        self.need_cut = False

    def close(self):
        self.fd.close()

    def write(self, data):
        if self.end:
            return

        if not self.next_count:
            if self.prev:
                data = self.prev + data

            if self.need_cut:
                if len(data) < 2:
                    self.prev = data
                    return
                data = data[2:]
                self.need_cut = False

            pos = data.find(b'\r\n')
            if pos < 0:
                self.prev = data
                return
            assert pos, repr(data)
            self.next_count = int(data[:pos], 16)
            if self.next_count == 0:
                self.end = True
                return
            self.prev = None
            self.need_cut = True
            data = data[pos+2:]

        data_to_write = data[:self.next_count]
        rest = data[self.next_count:]
        self.next_count -= len(data_to_write)
        self.fd.write(data_to_write)
        if rest:
            self.write(rest)



async def handle_client(client):
    req, pos = await recv_until(client, b'\r\n\r\n')
    if pos < 0:
        raise Exception(f'Invalid proto {req}')
    assert len(req) - pos == 4
    (method, url, _), _ = parse_http_line(req)

    fname = get_cache_path(url)
    if os.path.exists(fname):
        print('HIT', url)
        with open(fname, 'rb') as fd:
            size = os.fstat(fd.fileno()).st_size
            headers = [b'Content-Length: %d' % size,
                       b'Connection: Close',
                       b'Content-Type: application/octet-stream']
            await sendall(client, b'HTTP/1.1 200 OK\r\n%s\r\n\r\n' % b'\r\n'.join(headers))
            while size > 0:
                count = await wait_io(client, WAIT_WRITE, os.sendfile,
                                      client.fileno(), fd.fileno(), None, size)
                size -= count
    else:
        print('MISS', method, url)
        h = await make_request(method, url)
        resp, offset = await recv_until(h.sock, b'\r\n\r\n')
        if offset < 0:
            raise Exception(f'Invalid proto {resp}')

        (_, status_code, _), resp_headers = parse_http_line(resp)

        for _ in range(5):
            if status_code in (b'301', b'302'):
                h.sock.close()
                new_url = get_header_value(resp_headers, b'location')
                h = await make_request(b'GET', new_url)
                resp, offset = await recv_until(h.sock, b'\r\n\r\n')
                if offset < 0:
                    raise Exception(f'Invalid proto {resp}')
                (_, status_code, _), resp_headers = parse_http_line(resp)
            else:
                break

        if status_code == b'200':
            fd = open(fname + b'.tmp', 'wb')
            if b'chunked' in get_header_value(resp_headers, b'transfer-encoding', b''):
                fd = ChunkedWriter(fd)
        else:
            fd = None

        if fd:
            fd.write(resp[offset+4:])
        await sendall(client, resp)

        while True:
            data = await recv(h.sock, BUF_SIZE)
            if not data:
                break
            if fd:
                fd.write(data)
            await sendall(client, data)

        h.sock.close()
        if fd:
            fd.close()
            os.rename(fname + b'.tmp', fname)

    # print('END', client)


def serve(bind):
    sock = socket.create_server(bind, backlog=128)
    sock.setblocking(False)

    async def forever():
        while True:
            s, _ = await accept(sock)
            s.setblocking(False)
            await spawn(handle_client(s))

    run(forever())


def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('-b', '--bind', metavar='[host]:port', default='127.0.0.1:3128')
    parser.add_argument('cache_dir', metavar='cache-dir')

    logging.basicConfig(level='INFO')

    args = parser.parse_args()

    host, _, port = args.bind.partition(':')
    if not host:
        host = '127.0.0.1'
    if not port:
        port = 3128

    global CACHE_DIR
    CACHE_DIR = args.cache_dir
    os.makedirs(CACHE_DIR, exist_ok=True)

    serve((host, int(port)))


if __name__ == '__main__':
    main()
